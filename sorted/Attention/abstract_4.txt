The rapid advancement of autonomous systems has led to increased research in sensor fusion and decision-making algorithms. These systems integrate data from multiple sensors, such as LiDAR, cameras, and IMUs, to perceive their surroundings and make real-time decisions. Deep learning models, particularly convolutional and transformer-based architectures, have significantly improved object detection and scene understanding. Despite these advancements, challenges such as environmental variability, data uncertainty, and real-time processing remain key areas of study. Future research focuses on enhancing robustness, reducing computational costs, and improving the adaptability of autonomous systems across diverse scenarios.